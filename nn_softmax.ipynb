{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:49:33.351758Z","iopub.status.busy":"2024-05-06T14:49:33.351343Z","iopub.status.idle":"2024-05-06T14:49:33.393751Z","shell.execute_reply":"2024-05-06T14:49:33.391970Z","shell.execute_reply.started":"2024-05-06T14:49:33.351726Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:49:33.397833Z","iopub.status.busy":"2024-05-06T14:49:33.397110Z","iopub.status.idle":"2024-05-06T14:49:33.434782Z","shell.execute_reply":"2024-05-06T14:49:33.433482Z","shell.execute_reply.started":"2024-05-06T14:49:33.397786Z"},"trusted":true},"outputs":[],"source":["# !conda install matplotlib\n","# !conda install numpy\n","# !conda install pandas\n","# !conda install scikit-learn\n","# !conda install tensorflow\n","# !pip install fasteda\n","# !conda install Jinja2 --y"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:49:33.436662Z","iopub.status.busy":"2024-05-06T14:49:33.436152Z","iopub.status.idle":"2024-05-06T14:49:33.472375Z","shell.execute_reply":"2024-05-06T14:49:33.470763Z","shell.execute_reply.started":"2024-05-06T14:49:33.436630Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","from sklearn.metrics import log_loss, accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","from src import load_data, categorical_to_numerical, numerical_scaling, encode_label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Settings\n","KAGGLE = False\n","CATEGORICAL_TO_NUMERICAL = True\n","ENCODE_LABEL = True\n","NUMERICAL_SCALING = True\n","\n","numerical_features = [\n","    \"N_Days\",\n","    \"Age\",\n","    \"Bilirubin\",\n","    \"Cholesterol\",\n","    \"Albumin\",\n","    \"Copper\",\n","    \"Alk_Phos\",\n","    \"SGOT\",\n","    \"Tryglicerides\",\n","    \"Platelets\",\n","    \"Prothrombin\",\n","    \"Stage\",\n","]\n","\n","categorical_features = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Edema\", \"Spiders\"]\n","\n","label_order = [\"C\", \"CL\", \"D\"]"]},{"cell_type":"markdown","metadata":{},"source":["## **Data**"]},{"cell_type":"markdown","metadata":{},"source":["#### Load Data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[X-train]: (7905, 18)\n","[y-train]: (7905,)\n","[X-test]: (5271, 18)\n","[y-test]: (5271, 4)\n"]}],"source":["df_X_train, df_X_test, df_y_train, df_y_test = load_data(KAGGLE)\n","\n","print(f\"[X-train]: {df_X_train.shape}\")\n","print(f\"[y-train]: {df_y_train.shape}\")\n","print(f\"[X-test]: {df_X_test.shape}\")\n","print(f\"[y-test]: {df_y_test.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Scaling"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["if CATEGORICAL_TO_NUMERICAL:\n","    # train subset\n","    df_X_train = categorical_to_numerical(\n","        df_X_train, categorical_features, transformer=\"ordinal\"\n","    ).copy(deep=True)\n","\n","    # test subset\n","    df_X_test = categorical_to_numerical(\n","        df_X_test, categorical_features, transformer=\"ordinal\"\n","    ).copy(deep=True)\n","\n","if ENCODE_LABEL:\n","    # this ensures that the label order is the same one as in sample_submission\n","    encoded_label = encode_label(df_y_train.values, label_order)\n","    df_y_train = pd.DataFrame(encoded_label, columns=[\"Status\"])"]},{"cell_type":"markdown","metadata":{},"source":["## **Model - Train, Validate, GridsearchCV**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# class BaseModel:\n","#     def fit(self, X, y, **kwargs):\n","#         \"\"\"Fit the model to the data. Specific arguments can be passed in kwargs.\"\"\"\n","#         raise NotImplementedError(\"This method should be implemented by subclasses.\")\n","\n","#     def predict(self, X):\n","#         \"\"\"Make predictions using the fitted model.\"\"\"\n","#         raise NotImplementedError(\"This method should be implemented by subclasses.\")"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["class SoftmaxRegressionNN:\n","    def __init__(self, **kwargs):\n","        self.model = self.compile(**kwargs)\n","\n","    def __getattr__(self, attr):\n","        \"\"\"\n","        Delegate attribute access to the underlying model if it's not found in this class.\n","        If it's a callable attribute, wrap it to modify behavior.\n","        \"\"\"\n","        orig_attr = getattr(self.model, attr)\n","        if callable(orig_attr):\n","\n","            def hooked(*args, **kwargs):\n","                # Modify args or kwargs here before passing them to the original function\n","                # For example, let's filter out kwargs for 'fit' method specifically\n","                if attr == \"fit\":\n","                    allowed_kwargs = [\n","                        \"epochs\",\n","                        \"batch_size\",\n","                        \"verbose\",\n","                        # \"callbacks\",\n","                        # \"validation_data\",\n","                    ]\n","                    kwargs_ = {k: v for k, v in kwargs.items() if k in allowed_kwargs}\n","\n","                # Now call the original attribute with potentially modified arguments\n","                return orig_attr(*args, **kwargs_)\n","\n","            return hooked\n","        else:\n","            return orig_attr\n","\n","    def compile(self, **kwargs) -> callable:\n","        allowed_kwargs = [\n","            \"learning_rate\",\n","        ]\n","        kwargs_ = {k: v for k, v in kwargs.items() if k in allowed_kwargs}\n","\n","        model = tf.keras.models.Sequential(\n","            layers=[\n","                tf.keras.layers.Dense(25, \"relu\"),\n","                tf.keras.layers.Dense(10, \"relu\"),\n","                tf.keras.layers.Dense(3, \"linear\"),\n","            ],\n","            name=\"idk\",\n","        )\n","\n","        model.compile(\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","            optimizer=tf.keras.optimizers.legacy.Adam(\n","                **kwargs_\n","            ),  # legacy.Adam - Adam runs slow on M1/M2 chips\n","            metrics=[\"sparse_categorical_crossentropy\"],\n","        )\n","\n","        return model\n","\n","    def predict(self, X: np.array, **kwargs) -> tuple[np.array, np.array]:\n","        allowed_kwargs = [\n","            \"verbose\",\n","        ]\n","        kwargs_ = {k: v for k, v in kwargs.items() if k in allowed_kwargs}\n","\n","        prediction = self.model.predict(X, **kwargs_)\n","        y_pred_proba = tf.nn.softmax(prediction).numpy()\n","        y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","        return y_pred, y_pred_proba"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class ScikitLearnModel:\n","#     def __init__(self, model):\n","#         self.model = model\n","\n","#     def fit(self, X, y, **kwargs):\n","#         # Filter for scikit-learn-specific arguments or ignore all kwargs\n","#         sklearn_args = {k: v for k, v in kwargs.items() if k in [\"sample_weight\"]}\n","#         self.model.fit(X, y, **sklearn_args)\n","\n","#     def predict(self, X):\n","#         return self.model.predict(X)"]},{"cell_type":"markdown","metadata":{},"source":["## **Cross-Validation: Stratified K-Fold**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Option to do standard procedure: train, dev, test (sequencially by ID order) (1 run)\n","# Option to do k-fold (stratified): train, dev, test (order via k-fold procedure) (2+ runs)\n","\n","# train - fit model\n","# dev - hyper-parameter tuning\n","# test - evaluate log-loss / accuracy / other metric"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, KFold\n","\n","\n","class CrossValidation:\n","    def __init__(\n","        self,\n","        df_X: pd.DataFrame,\n","        df_y: pd.DataFrame,\n","        numerical_scale: bool,\n","        numerical_features: list = None,\n","    ) -> None:\n","        \"\"\" \"\"\"\n","        self.X = df_X.values\n","        self.y = df_y.values\n","\n","        self.n_features = df_X.shape[1]\n","        self.numerical_scale = numerical_scale\n","\n","        if numerical_features is not None:\n","            self.numerical_indexes = self.get_numerical_indexes(\n","                df_X, numerical_features\n","            )\n","            self.categorical_indexes = self.get_categorical_indexes()\n","\n","    def get_numerical_indexes(\n","        self, df_X: pd.DataFrame, num_features: list\n","    ) -> list[int]:\n","        \"\"\" \"\"\"\n","        if self.numerical_scale:\n","            return [df_X.columns.get_loc(column) for column in num_features]\n","        else:\n","            return []\n","\n","    def get_categorical_indexes(self) -> list[int]:\n","        \"\"\" \"\"\"\n","        if self.numerical_scale:\n","            return list(set(np.arange(self.n_features)) - set(self.numerical_indexes))\n","        else:\n","            return []\n","\n","    def check_numerical_scaling(\n","        self, X_train: np.array, X_validation: np.array\n","    ) -> tuple[np.array, np.array]:\n","        \"\"\" \"\"\"\n","\n","        if self.numerical_scale:\n","            transformed_data, numerical_transformer = numerical_scaling(\n","                X_train[:, self.numerical_indexes], None\n","            )\n","\n","            X_train = np.concatenate(\n","                (transformed_data, X_train[:, self.categorical_indexes]), axis=1\n","            )\n","\n","            transformed_data, _ = numerical_scaling(\n","                X_validation[:, self.numerical_indexes], numerical_transformer\n","            )\n","\n","            X_validation = np.concatenate(\n","                (transformed_data, X_validation[:, self.categorical_indexes]), axis=1\n","            )\n","\n","        return X_train, X_validation\n","\n","    def one_split(\n","        self, train_index: np.array, validation_index: np.array\n","    ) -> tuple[float, float]:\n","        \"\"\" \"\"\"\n","\n","        # split in train and validation subsets\n","        X_train, X_validation = self.X[train_index], self.X[validation_index]\n","        y_train, y_validation = self.y[train_index], self.y[validation_index]\n","\n","        X_train, X_validation = self.check_numerical_scaling(X_train, X_validation)\n","\n","        # fit model\n","        self.model.fit(X_train, y_train, **self.kwargs)\n","\n","        # predict label\n","        y_pred, y_pred_proba = self.model.predict(X_validation, **self.kwargs)\n","\n","        # predict evaluation metrics\n","        acc = accuracy_score(y_validation, y_pred)\n","        ll = log_loss(y_validation, y_pred_proba)\n","\n","        return acc, ll\n","\n","    def run(\n","        self,\n","        model: callable,\n","        split_method: str = \"standard\",\n","        shuffle: bool = False,\n","        random_state: float = None,\n","        n_splits: int = 5,\n","        test_size: float = 0.3,\n","        **kwargs,\n","    ):\n","        \"\"\"\n","        Execute the cross-validation process with the specified model and splitting strategy.\n","\n","        Parameters:\n","        - model (callable): The machine learning model to train and evaluate.\n","        - split_method (str): The type of cross-validation split ('standard', 'kfold', 'stratified_kfold').\n","        - shuffle (bool): Whether to shuffle data before splitting.\n","        - random_state (int, optional): Seed for random number generator.\n","        - n_splits (int): Number of folds for k-fold strategies.\n","        - test_size (float): Proportion of the dataset to include in the test split (for 'standard' strategy).\n","        - kwargs: Additional keyword arguments to pass to the model training method.\n","\n","        Returns:\n","        - dict: Dictionary containing accuracy and log loss history and their averages.\n","        \"\"\"\n","\n","        self.model = model\n","        self.kwargs = kwargs\n","\n","        if split_method == \"standard\":\n","            indexes = np.arange(self.X.shape[0])\n","            splits = [\n","                train_test_split(\n","                    indexes, test_size=test_size, random_state=random_state\n","                )\n","            ]\n","        elif split_method == \"kfold\":\n","            kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n","            splits = kf.split(self.X, self.y)\n","        elif split_method == \"stratified_kfold\":\n","            skf = StratifiedKFold(\n","                n_splits=n_splits, shuffle=shuffle, random_state=random_state\n","            )\n","            splits = skf.split(self.X, self.y)\n","        else:\n","            raise ValueError(f\"Unsupported split method: {split_method}\")\n","\n","        self.history = {\"accuracy\": [], \"log_loss\": []}\n","        for train_index, validation_index in splits:\n","            acc, ll = self.one_split(train_index, validation_index)\n","\n","            self.history[\"accuracy\"].append(acc)\n","            self.history[\"log_loss\"].append(ll)\n","\n","        self.history[\"avg_accuracy\"] = np.mean(self.history[\"accuracy\"])\n","        self.history[\"avg_log_loss\"] = np.mean(self.history[\"log_loss\"])\n","\n","        return self.history"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# param_options = {\"learning_rate\": [0.1, 0.01, 0.001, 0.0001], \"epochs\": [30, 50, 100]}\n","# for model in models:\n","#     model.fit(X_train, y_train, **kwargs)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'learning_rate': 0.01, 'epochs': 30, 'batch_size': 50, 'verbose': 0}\n","[0.01399035 0.13731262 0.848697  ]\n","[Validation Set] Average Accuracy: 78.92 %\n","[Validation Set] Average Log-loss: 0.54 \n","\n","{'learning_rate': 0.01, 'epochs': 30, 'batch_size': 70, 'verbose': 0}\n","[0.98375064 0.01158628 0.00466314]\n","[Validation Set] Average Accuracy: 79.76 %\n","[Validation Set] Average Log-loss: 0.53 \n","\n","{'learning_rate': 0.01, 'epochs': 50, 'batch_size': 50, 'verbose': 0}\n","[0.93076366 0.00870962 0.06052677]\n","[Validation Set] Average Accuracy: 77.87 %\n","[Validation Set] Average Log-loss: 0.61 \n","\n","{'learning_rate': 0.01, 'epochs': 50, 'batch_size': 70, 'verbose': 0}\n","[0.06579856 0.02496652 0.90923494]\n","[Validation Set] Average Accuracy: 80.82 %\n","[Validation Set] Average Log-loss: 0.59 \n","\n","{'learning_rate': 0.001, 'epochs': 30, 'batch_size': 50, 'verbose': 0}\n","[0.9754288  0.01470015 0.00987106]\n","[Validation Set] Average Accuracy: 80.44 %\n","[Validation Set] Average Log-loss: 0.51 \n","\n","{'learning_rate': 0.001, 'epochs': 30, 'batch_size': 70, 'verbose': 0}\n","[0.09525469 0.03766186 0.86708343]\n","[Validation Set] Average Accuracy: 79.13 %\n","[Validation Set] Average Log-loss: 0.51 \n","\n","{'learning_rate': 0.001, 'epochs': 50, 'batch_size': 50, 'verbose': 0}\n","[0.8564846  0.03236065 0.11115472]\n","[Validation Set] Average Accuracy: 80.73 %\n","[Validation Set] Average Log-loss: 0.50 \n","\n","{'learning_rate': 0.001, 'epochs': 50, 'batch_size': 70, 'verbose': 0}\n","[0.58068454 0.04453199 0.3747835 ]\n","[Validation Set] Average Accuracy: 80.90 %\n","[Validation Set] Average Log-loss: 0.50 \n","\n"]}],"source":["import itertools\n","\n","gridsearch_kwargs = {\n","    \"learning_rate\": [0.01, 0.001],\n","    \"epochs\": [30, 50],\n","    \"batch_size\": [50, 70],\n","    \"verbose\": [0],\n","}\n","\n","# Create a list of keys and a list of lists of values\n","keys = list(gridsearch_kwargs.keys())\n","values = list(gridsearch_kwargs.values())\n","\n","# Generate all combinations of the parameter values\n","all_combinations = itertools.product(*values)\n","\n","# Print each combination as a formatted dictionary\n","for combination in all_combinations:\n","    kwargs = dict(zip(keys, combination))\n","    print(kwargs)\n","\n","    model = SoftmaxRegressionNN(**kwargs)\n","\n","    cv = CrossValidation(\n","        df_X_train,\n","        df_y_train[\"Status\"],\n","        numerical_scale=True,\n","        numerical_features=numerical_features,\n","    )\n","\n","    history = cv.run(\n","        model, \"standard\", shuffle=True, random_state=None, **kwargs\n","    )\n","\n","    print(\n","        \"[Validation Set] Average Accuracy: %.2f\" % (history[\"avg_accuracy\"] * 100), \"%\"\n","    )\n","    print(\"[Validation Set] Average Log-loss: %.2f \\n\" % history[\"avg_log_loss\"])"]},{"cell_type":"markdown","metadata":{},"source":["## **Predict Test Sample**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:49:36.242660Z","iopub.status.busy":"2024-05-06T14:49:36.241012Z","iopub.status.idle":"2024-05-06T14:49:36.286657Z","shell.execute_reply":"2024-05-06T14:49:36.284158Z","shell.execute_reply.started":"2024-05-06T14:49:36.242595Z"},"trusted":true},"outputs":[],"source":["# y_test_proba = models[\"log_reg\"].predict_proba(X_test)\n","\n","# Neural network\n","prediction = model.predict(X_test)\n","y_test_pred_proba = tf.nn.softmax(prediction)\n","\n","\n","# Prepare submission DataFrame\n","df_y_test_pred_proba = pd.DataFrame(\n","    y_test_pred_proba, columns=[\"Status_C\", \"Status_CL\", \"Status_D\"]\n",")\n","\n","df_y_test_pred_proba = pd.concat([df_y_test[\"id\"], df_y_test_pred_proba], axis=1)\n","\n","display(df_y_test_pred_proba.head())\n","display(df_y_test_pred_proba.tail())"]},{"cell_type":"markdown","metadata":{},"source":["## **Submission**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:50:08.309441Z","iopub.status.busy":"2024-05-06T14:50:08.308932Z","iopub.status.idle":"2024-05-06T14:50:08.394384Z","shell.execute_reply":"2024-05-06T14:50:08.393064Z","shell.execute_reply.started":"2024-05-06T14:50:08.309404Z"},"trusted":true},"outputs":[],"source":["if KAGGLE:\n","    # Save submission to a CSV file\n","    df_y_test_pred_proba.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["**NEXT STEPS**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T14:49:36.204447Z","iopub.status.busy":"2024-05-06T14:49:36.204047Z","iopub.status.idle":"2024-05-06T14:49:36.239400Z","shell.execute_reply":"2024-05-06T14:49:36.238420Z","shell.execute_reply.started":"2024-05-06T14:49:36.204415Z"},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7000181,"sourceId":60893,"sourceType":"competition"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
