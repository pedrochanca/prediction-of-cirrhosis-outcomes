{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    LabelEncoder,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"kaggle\": False,\n",
    "    \"categorical_features\": [\n",
    "        \"Drug\",\n",
    "        \"Sex\",\n",
    "        \"Ascites\",\n",
    "        \"Hepatomegaly\",\n",
    "        \"Edema\",\n",
    "        \"Spiders\",\n",
    "        \"Stage\"\n",
    "    ],\n",
    "    \"numerical_features\": [\n",
    "        \"N_Days\",\n",
    "        \"Age\",\n",
    "        \"Bilirubin\",\n",
    "        \"Cholesterol\",\n",
    "        \"Albumin\",\n",
    "        \"Copper\",\n",
    "        \"Alk_Phos\",\n",
    "        \"SGOT\",\n",
    "        \"Tryglicerides\",\n",
    "        \"Platelets\",\n",
    "        \"Prothrombin\",\n",
    "        \"Stage\",\n",
    "    ],\n",
    "    \"target\": \"Status\",\n",
    "    \"label_order\": [\"D\", \"CL\", \"C\"],\n",
    "    \"random_seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-Process Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(kaggle: bool) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    if kaggle:\n",
    "        train = pd.read_csv(\"/kaggle/input/playground-series-s3e26/train.csv\")\n",
    "        test = pd.read_csv(\"/kaggle/input/playground-series-s3e26/test.csv\")\n",
    "        sub = pd.read_csv(\"/kaggle/input/playground-series-s3e26/sample_submission.csv\")\n",
    "    else:\n",
    "        train = pd.read_csv(\"./data/train.csv\")\n",
    "        test = pd.read_csv(\"./data/test.csv\")\n",
    "        sub = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "    return train, test, sub\n",
    "\n",
    "\n",
    "def get_numerical_and_categorical_indexes(\n",
    "    df: pd.DataFrame, numerical_features: list[str]\n",
    ") -> tuple[list, list]:\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    n_features = df.shape[1]\n",
    "\n",
    "    numerical_indexes = [df.columns.get_loc(column) for column in numerical_features]\n",
    "\n",
    "    categorical_indexes = list(set(np.arange(n_features)) - set(numerical_indexes))\n",
    "\n",
    "    return numerical_indexes, categorical_indexes\n",
    "\n",
    "\n",
    "def categorical_preprocess(\n",
    "    df: pd.DataFrame, features: list[str], encoder: str\n",
    ") -> pd.DataFrame:\n",
    "    df_ = df.copy(deep=True)\n",
    "\n",
    "    if encoder == \"ordinal\":\n",
    "        encoder = OrdinalEncoder(handle_unknown=\"error\")\n",
    "    elif encoder == \"one-hot\":\n",
    "        encoder = OneHotEncoder(handle_unknown=\"error\")\n",
    "\n",
    "    df_[features] = encoder.fit_transform(df_[features])\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def target_preprocess(\n",
    "    df: pd.DataFrame, target: str, label_order: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    df_ = df.copy(deep=True)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label_order)\n",
    "\n",
    "    df_[target] = encoder.transform(df_[target])\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def numerical_preprocess(\n",
    "    x_train: np.array,\n",
    "    x_test: np.array,\n",
    "    numerical_indexes: list,\n",
    ") -> tuple[np.array, np.array]:\n",
    "    scaler = NumericalScaling(numerical_indexes)\n",
    "\n",
    "    x_train = scaler.run(x_train, use_saved_transformer=False)\n",
    "    x_test = scaler.run(x_test, use_saved_transformer=True)\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "class NumericalScaling:\n",
    "    def __init__(self, numerical_indexes: list):\n",
    "        self.numerical_indexes = numerical_indexes\n",
    "\n",
    "    def run(self, x_values: np.array, use_saved_transformer: bool) -> np.array:\n",
    "        if not use_saved_transformer:\n",
    "            # create transformer\n",
    "            self.transformer = StandardScaler()\n",
    "\n",
    "            # fit the transformer and get scaled data\n",
    "            x_values[:, self.numerical_indexes] = self.transformer.fit_transform(\n",
    "                x_values[:, self.numerical_indexes]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # scale data using existing transformer\n",
    "            x_values[:, self.numerical_indexes] = self.transformer.transform(\n",
    "                x_values[:, self.numerical_indexes]\n",
    "            )\n",
    "            \n",
    "        return x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, sub = load_data(config[\"kaggle\"])\n",
    "\n",
    "config[\"numerical_indexes\"], config[\"categorical_indexes\"] = (\n",
    "    get_numerical_and_categorical_indexes(\n",
    "        train.drop([\"id\", \"Status\"], axis=1), config[\"numerical_features\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# order features list according to default order\n",
    "config[\"features\"] = [\n",
    "    col\n",
    "    for col in train.columns\n",
    "    if col in config[\"numerical_features\"] + config[\"categorical_features\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each DataFrame\n",
    "for df_name in [\"train\", \"test\"]:\n",
    "    globals()[df_name] = categorical_preprocess(\n",
    "        globals()[df_name], config[\"categorical_features\"], \"ordinal\"\n",
    "    )\n",
    "\n",
    "    if df_name == \"train\":\n",
    "        globals()[df_name] = target_preprocess(\n",
    "            globals()[df_name], config[\"target\"], config[\"label_order\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    train[config[\"features\"]].values,\n",
    "    train[config[\"target\"]].values,\n",
    "    test_size=0.3,\n",
    "    random_state=config[\"random_seed\"],\n",
    ")\n",
    "\n",
    "x_train, x_test = numerical_preprocess(\n",
    "    x_train, x_test, config[\"numerical_indexes\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Grid Search + Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- iterations : number of boosting iterations (trees) to be used.\n",
    "- learning_rate : controls the step size at each iteration while moving toward a minimum of the loss function.\n",
    "- max_depth : maximum depth of individual trees.\n",
    "- min_child_samples: minimum numberearly_stopping_rounds of samples required to be at a leaf node.\n",
    "- early_stopping_rounds : number of rounds with no improvement after which training will be stopped.\n",
    "- reg_lambda: L2 regularization term on weighs.\n",
    "- subsample : Fraction of samples to use for fitting each tree, providing a trade-off between model robustness and randomness.\n",
    "- bootstrap_type : Controls the method used to sample data for each tree in the ensemble.\n",
    "\"\"\"\n",
    "\n",
    "if not config[\"kaggle\"]:\n",
    "    param_grid = {\n",
    "        \"iterations\": [50, 100, 200, 250, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.25, 0.5],\n",
    "        \"max_depth\": [5, 7, 9],\n",
    "        # \"min_child_samples\": [10, 15, 20],\n",
    "        \"early_stopping_rounds\": [20],\n",
    "        \"reg_lambda\": [0.5, 0.6, 0.65, 0.7],\n",
    "        # \"subsample\": [0.6, 0.8, 1],\n",
    "        # \"bootstrap_type\": [\"Bernoulli\"]\n",
    "    }\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        objective=\"MultiClass\",\n",
    "        random_seed=config[\"random_seed\"],\n",
    "        verbose=False,\n",
    "    )\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "    results = grid_search.fit(x_train, y_train, plot=False)\n",
    "    results.best_estimator_.get_params(), results.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"iterations\": 250,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 5,\n",
    "    \"reg_lambda\": 0.65,\n",
    "    \"objective\": \"MultiClass\",\n",
    "    \"early_stopping_rounds\": 20,\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**parameters)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred_proba = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.34 % | Log Loss: 0.4536 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "ll = log_loss(y_test, y_test_pred_proba)\n",
    "\n",
    "print(\n",
    "    \"Accuracy: %.2f\" % (acc * 100),\n",
    "    \"%\",  \"| Log Loss: %.4f \\n\" % ll\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Kaggle Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"kaggle\"]:\n",
    "    # pre-process data\n",
    "    x_train_sub = train[config[\"features\"]].values\n",
    "    y_train_sub = train[config[\"target\"]].values\n",
    "    x_test_sub = test[config[\"features\"]].values\n",
    "\n",
    "    x_train_sub, x_test_sub = numerical_preprocess(\n",
    "        x_train_sub, x_test_sub, config[\"numerical_indexes\"], config[\"categorical_indexes\"]\n",
    "    )\n",
    "\n",
    "    # fit model\n",
    "    model = CatBoostClassifier(**parameters)\n",
    "    model.fit(x_train_sub, y_train_sub)\n",
    "\n",
    "    # predict y_values\n",
    "    y_test_pred_sub = model.predict(x_test_sub)\n",
    "    y_test_pred_proba_sub = model.predict_proba(x_test_sub)\n",
    "\n",
    "    # create submission dataframe\n",
    "    submission = pd.DataFrame(\n",
    "        y_test_pred_proba_sub, columns=[\"Status_D\", \"Status_CL\", \"Status_C\"]\n",
    "    )\n",
    "    submission = pd.concat([test[\"id\"], submission], axis=1)\n",
    "\n",
    "    # save submission to a CSV file\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
